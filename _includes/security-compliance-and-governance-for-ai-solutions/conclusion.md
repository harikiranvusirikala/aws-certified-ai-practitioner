# Course: Security, Compliance, and Governance for AI Solutions (Domain 5)

## Compliance Standards
- National Institute of Standards and Technology (NIST)
- European Union Agency for Cybersecurity (ENISA)
- International Organization for Standardization (ISO)
- AWS System and Organization Controls (SOC)
- Health Insurance Portability and Accountability Act (HIPAA)
- General Data Protection Regulation (GDPR)
- Payment Card Industry Data Security Standard (PCI DSS)
- Algorithmic Accountability Act

## AWS Services for Governance and Compliance

| Service | Usage |
|:--|:--|
| AWS Config | view of configuration |
| Amazon Inspector | vulnerability management |
| AWS Audit Manager | manage risk and compliance |
| AWS Artifact | AWS security and compliance documents |
| AWS CloudTrail | log of actions |
| AWS Trusted Advisor | cost, performance, security, resillience, operational excellence, and service limits |

## Data Governance Strategies
- Data quality and integrity
- Data protection and privacy
- Data lifecycle management
- Responsible AI
- Governance structures and roles
- Data sharing and collaboration

## Concepts in Data governance
- Data lifecycles
- Data logging
- Data residency - physical location where data is stored and processed.
- Data monitoring
- Data analysis
- Data retention

## Approaches to governance strategies
- Policies
- Review cadence - Implement a regular review process to assess the performance, safety, and responsible AI implications of the generative AI solutions.
- Review strategies
- Transparency standards
- Team training requirements

## Key aspects to consider when monitoring an AI system.
- Performance metrics
	- Model accuracy: The proportion of correct predictions made by the model
	- Precision: The ratio of true positive predictions to the total number of "positive predictions made by the model"
	- Recall: The ratio of true positive predictions to the total number of "actual positive instances in the data"
	- F1-score: The harmonic mean of precision and recall, which provides a balanced measure of model performance
	- Latency: The time taken by the model to make a prediction, which is an important measure of a model's practical performance
- Infrastructure monitoring
- Monitoring for bias and fairness
- Monitoring for compliance and responsible AI

## Generative AI Security Scoping Matrix

| Scope | Info |
|:--|:--|
| Scope 1: Consumer app        | Using public generative AI services |
| Scope 2: Enterprise app        | Using an app or SaaS with generative AI features |
| Scope 3: Pre-trained models | Building your app on a versioned model |
| Scope 4: Fine-tuned models  | Fine-tuning a model on your data |
| Scope 5: Self-trained models | Training a model from scratch on your data |
