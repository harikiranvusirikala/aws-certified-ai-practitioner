Security and Privacy Considerations for AI Systems
  5.1.d
  Security considerations
    • Threat detection
      • Identify and monitor for potential security threats, such as malicious actors attempting to exploit vulnerabilities in AI systems or using generative AI for malicious purposes. The following are some examples:
        • Generating fake content
        • Manipulating data
        • Automating attacks
      • You can assist threat detection by developing and deploying AI-powered threat detection systems. You can analyze network traffic, user behavior, and other data sources to detect and respond to potential threats.
    • Vulnerability management
      • Identify and address vulnerabilities in AI and generative AI systems, including software bugs, model weaknesses, and potential attack vectors (for example, malware, viruses, and email attachments).
      • Regularly conduct security assessments, "penetration testing" (attempt to find and exploit vulnerabilities), and code reviews to uncover and address vulnerabilities.
      • Implement robust "patch management" and update processes to ensure that AI systems are kept up to date and secure.
    • Infrastructure protection
      • Secure the underlying infrastructure that supports AI and generative AI systems, such as Cloud computing platforms, Edge devices and Data stores.
      • Implement strong access controls, network segmentation, encryption, and other security measures to protect the infrastructure from unauthorized access and attacks.
      • Ensure that the AI infrastructure is resilient and can withstand failures, attacks, or other disruptions.
    • Prompt injection
        adversaries attempt to manipulate the input prompts of generative AI models to generate malicious or undesirable content.
      • Employ techniques, such as "prompt filtering", "sanitization", and validation, to ensure that the input prompts are safe and do not contain malicious content.
      • Develop robust models and training procedures that are resistant to prompt injection attacks.
    • Data encryption
      • Implement strong encryption mechanisms to secure both "data at rest" and "data in transit".
      • Ensure that the encryption keys are properly managed and protected from unauthorized access.

  The Open Web Application Security Project (OWASP) Top 10 for LLMs
    industry standard list of the top 10 vulnerabilities that can impact a generative AI LLM system
    1. Prompt injection: Malicious user inputs that can manipulate the behavior of a language model
    2. Insecure output handling: Failure to properly sanitize or validate model outputs, leading to security vulnerabilities
    3. Training data poisoning: Introducing malicious data into a model's training set, causing it to learn harmful behaviors
    4. Model denial of service: Techniques that exploit vulnerabilities in a model's architecture to disrupt its availability
    5. Supply chain vulnerabilities: Weaknesses in the software, hardware, or services used to build or deploy a model
    6. Sensitive information disclosure: Leakage of sensitive data through model outputs or other unintended channels
    7. Insecure plugin design: Flaws in the design or implementation of optional model components that can be exploited
    8. Excessive agency: Granting a model too much autonomy or capability, leading to unintended and potentially harmful actions
    9. Overreliance: Over-dependence on a model's capabilities, leading to over-trust and failure to properly audit its outputs
    10. Model theft: Unauthorized access or copying of a model's parameters or architecture, allowing for its reuse or misuse

5.1.a
AWS Services and Features for Securing AI Systems
  Reasons for securing an AI system
    • AI models process sensitive data
    • AI Systems can be vulnerable to adversarial attacks
    • AI systems are increasingly integration into critical applications and decision-making processes
  The AWS Shared Responsibility Model
    The customer assumes responsibility and management of the guest operating system. This includes updates, security patches, and other associated application software, in addition to the configuration of the AWS provided security group firewall. 
    A customer's responsibility will be determined by the AWS Cloud services that a customer selects. This determines the amount of configuration work the customer must perform as part of their security responsibilities.
    Responsibility for "security IN the cloud".

    AWS operates, manages, and controls the host operating system and virtualization layer down to the physical security of the facilities in which the service operates.
    Responsibility for "security OF the cloud".
    <SharedResponsibilityModel-Final.jpg>
  AWS services for securing AI systems
    Defense in depth security
      (discussed previously)
      Four foundational AWS security services recommended for any workload, any customer, and any industry.
        • AWS Security Hub - incident response
            provides customers with a single dashboard to view all security findings, and to create and run automated playbooks.
        • AWS KMS - data protection
            encrypts data and gives customers the choice and control of using AWS managed keys or customer-managed keys to protect their data.
        • Amazon GuardDuty - threat detection
            threat detection service that monitors for suspicious activity and unauthorized behavior to protect AWS accounts, workloads, and data.
        • AWS Shield Advanced - network and application protection
            helps protect workloads against Distributed Denial of Service (DDoS) events.
            includes AWS WAF and AWS Firewall Manager.
    AWS security services
      • Identify sensitive data before training models - Amazon Macie
          "Amazon Macie" uses ML to automate sensitive data discovery at scale.
      • Manage identities and access to AWS services and resources - IAM
          "IAM", also centrally manage fine-grained permissions, and analyze access to refine permissions across AWS.
      • Limit access to your data, models, and outputs - AWS IAM Identity Center, IAM Access Analyzer, AWS Verified Access, Amazon Verified Permissions and Amazon SageMaker Role Manager
          Apply a policy of least privilege to training data, models, and applications using "AWS IAM Identity Center" (formerly SSO) and "IAM Access Analyzer".
          Explore further zero trust capabilities to add fine-grained access controls with AWS Verified Access and Amazon Verified Permissions. 
          Use "AWS Verified Access" to further eliminate the costs, complexity and performance issues related to virtual private networks (VPNs). 
          use "Amazon SageMaker Role Manager" to build and manage persona-based IAM roles for common ML needs.
          Note:
            "AWS Verified Access" focuses on secure remote access to corporate applications and resources without a VPN.
            "Amazon Verified Permissions" is a fine-grained permissions management and authorization service for custom applications built by you. 
      • Protect data from exfiltration (data theft) and manipulation
          Network Firewall, Amazon VPC and it's policies, AWS PrivateLink
      • Protect AI workloads with intelligent threat detection
          Amazon GuardDuty, Amazon Inspector and Amazon Detective
      • Automate incident response and compliance
          AWS Security Hub, AWS Config, AWS Audit Manager and AWS Artifact
      • Defend your generative AI web applications and data
          AWS Shield Advanced, AWS Firewall Manager, and AWS WAF and it's AWS WAF Bot Control
      (in detail in course)

5.1.b
Understanding Data and Model Lineage
  Data and model lineage refer to the detailed record of the origin, transformation, and evolution of data and models used in AI and generative AI systems. This information is important for understanding the origin, reliability, and potential biases or limitations of the data and models used in these systems.
  • Source citation
      act of properly attributing and acknowledging the sources of the data used to train the model.
      It is necessary to identify the sources from which the training data was collected, such as the following: 
        • Datasets
        • Databases
        • Other sources
      In addition, it is necessary to identify any relevant licenses, terms of use, or permissions associated with the data.
      helps assess the "reliability" and "trustworthiness" of the output.
  • Documenting data origins
      providing detailed information about the provenance, or the place of origin of the data used to train the model.
      This includes the following:
        • Details about the data collection process
        • The methods used to curate and clean the data
        • Any preprocessing or transformations applied to the data
      Documenting the data origins is important for understanding the "potential biases, limitations, or quality issues" that might be present in the training data. This can ultimately impact the "performance" and "reliability" of the generative AI model.
  Tools and techniques
   • Data lineage
   • Cataloging
   • Model cards
   "Amazon SageMaker Model Cards"
      document critical details about your ML models in a single place for streamlined governance and reporting.
      Model cards can catalog details, such as the intended use and risk rating of a model, training details and metrics, evaluation results and observations.
      It also catalogs additional call-outs such as considerations, recommendations, and custom information.
      By creating model cards, you can do the following:
        • Provide guidance on how a model should be used.
        • Support audit activities with detailed descriptions of model training and performance.
        • Communicate how a model is intended to support business goals.

