Security and Privacy Considerations for AI Systems
  5.1.d
  Security considerations
    • Threat detection
      • Identify and monitor for potential security threats, such as malicious actors attempting to exploit vulnerabilities in AI systems or using generative AI for malicious purposes. The following are some examples:
        • Generating fake content
        • Manipulating data
        • Automating attacks
      • You can assist threat detection by developing and deploying AI-powered threat detection systems. You can analyze network traffic, user behavior, and other data sources to detect and respond to potential threats.
    • Vulnerability management
      • Identify and address vulnerabilities in AI and generative AI systems, including software bugs, model weaknesses, and potential attack vectors (for example, malware, viruses, and email attachments).
      • Regularly conduct security assessments, "penetration testing" (attempt to find and exploit vulnerabilities), and code reviews to uncover and address vulnerabilities.
      • Implement robust "patch management" and update processes to ensure that AI systems are kept up to date and secure.
    • Infrastructure protection
      • Secure the underlying infrastructure that supports AI and generative AI systems, such as Cloud computing platforms, Edge devices and Data stores.
      • Implement strong access controls, network segmentation, encryption, and other security measures to protect the infrastructure from unauthorized access and attacks.
      • Ensure that the AI infrastructure is resilient and can withstand failures, attacks, or other disruptions.
    • Prompt injection
        adversaries attempt to manipulate the input prompts of generative AI models to generate malicious or undesirable content.
      • Employ techniques, such as "prompt filtering", "sanitization", and validation, to ensure that the input prompts are safe and do not contain malicious content.
      • Develop robust models and training procedures that are resistant to prompt injection attacks.
    • Data encryption
      • Implement strong encryption mechanisms to secure both "data at rest" and "data in transit".
      • Ensure that the encryption keys are properly managed and protected from unauthorized access.

  The Open Web Application Security Project (OWASP) Top 10 for LLMs
    industry standard list of the top 10 vulnerabilities that can impact a generative AI LLM system
    1. Prompt injection: Malicious user inputs that can manipulate the behavior of a language model
    2. Insecure output handling: Failure to properly sanitize or validate model outputs, leading to security vulnerabilities
    3. Training data poisoning: Introducing malicious data into a model's training set, causing it to learn harmful behaviors
    4. Model denial of service: Techniques that exploit vulnerabilities in a model's architecture to disrupt its availability
    5. Supply chain vulnerabilities: Weaknesses in the software, hardware, or services used to build or deploy a model
    6. Sensitive information disclosure: Leakage of sensitive data through model outputs or other unintended channels
    7. Insecure plugin design: Flaws in the design or implementation of optional model components that can be exploited
    8. Excessive agency: Granting a model too much autonomy or capability, leading to unintended and potentially harmful actions
    9. Overreliance: Over-dependence on a model's capabilities, leading to over-trust and failure to properly audit its outputs
    10. Model theft: Unauthorized access or copying of a model's parameters or architecture, allowing for its reuse or misuse

5.1.a
AWS Services and Features for Securing AI Systems
  Reasons for securing an AI system
    • AI models process sensitive data
    • AI Systems can be vulnerable to adversarial attacks
    • AI systems are increasingly integration into critical applications and decision-making processes
  The AWS Shared Responsibility Model
    The customer assumes responsibility and management of the guest operating system. This includes updates, security patches, and other associated application software, in addition to the configuration of the AWS provided security group firewall. 
    A customer's responsibility will be determined by the AWS Cloud services that a customer selects. This determines the amount of configuration work the customer must perform as part of their security responsibilities.
    Responsibility for "security IN the cloud".

    AWS operates, manages, and controls the host operating system and virtualization layer down to the physical security of the facilities in which the service operates.
    Responsibility for "security OF the cloud".
    <SharedResponsibilityModel-Final.jpg>
  AWS services for securing AI systems
    Defense in depth security
      (discussed previously)
      Four foundational AWS security services recommended for any workload, any customer, and any industry.
        • AWS Security Hub - incident response
            provides customers with a single dashboard to view all security findings, and to create and run automated playbooks.
        • AWS KMS - data protection
            encrypts data and gives customers the choice and control of using AWS managed keys or customer-managed keys to protect their data.
        • Amazon GuardDuty - threat detection
            threat detection service that monitors for suspicious activity and unauthorized behavior to protect AWS accounts, workloads, and data.
        • AWS Shield Advanced - network and application protection
            helps protect workloads against Distributed Denial of Service (DDoS) events.
            includes AWS WAF and AWS Firewall Manager.
    AWS security services
      • Identify sensitive data before training models - Amazon Macie
          "Amazon Macie" uses ML to automate sensitive data discovery at scale.
      • Manage identities and access to AWS services and resources - IAM
          "IAM", also centrally manage fine-grained permissions, and analyze access to refine permissions across AWS.
      • Limit access to your data, models, and outputs - AWS IAM Identity Center, IAM Access Analyzer, AWS Verified Access, Amazon Verified Permissions and Amazon SageMaker Role Manager
          Apply a policy of least privilege to training data, models, and applications using "AWS IAM Identity Center" (formerly SSO) and "IAM Access Analyzer".
          Explore further zero trust capabilities to add fine-grained access controls with AWS Verified Access and Amazon Verified Permissions. 
          Use "AWS Verified Access" to further eliminate the costs, complexity and performance issues related to virtual private networks (VPNs). 
          use "Amazon SageMaker Role Manager" to build and manage persona-based IAM roles for common ML needs.
          Note:
            "AWS Verified Access" focuses on secure remote access to corporate applications and resources without a VPN.
            "Amazon Verified Permissions" is a fine-grained permissions management and authorization service for custom applications built by you. 
      • Protect data from exfiltration (data theft) and manipulation
          Network Firewall, Amazon VPC and it's policies, AWS PrivateLink
      • Protect AI workloads with intelligent threat detection
          Amazon GuardDuty, Amazon Inspector and Amazon Detective
      • Automate incident response and compliance
          AWS Security Hub, AWS Config, AWS Audit Manager and AWS Artifact
      • Defend your generative AI web applications and data
          AWS Shield Advanced, AWS Firewall Manager, and AWS WAF and it's AWS WAF Bot Control
      (in detail in course)

5.1.b
Understanding Data and Model Lineage
  Data and model lineage refer to the detailed record of the origin, transformation, and evolution of data and models used in AI and generative AI systems. This information is important for understanding the origin, reliability, and potential biases or limitations of the data and models used in these systems.
  • Source citation
      act of properly attributing and acknowledging the sources of the data used to train the model.
      It is necessary to identify the sources from which the training data was collected, such as the following: 
        • Datasets
        • Databases
        • Other sources
      In addition, it is necessary to identify any relevant licenses, terms of use, or permissions associated with the data.
      helps assess the "reliability" and "trustworthiness" of the output.
  • Documenting data origins
      providing detailed information about the provenance, or the place of origin of the data used to train the model.
      This includes the following:
        • Details about the data collection process
        • The methods used to curate and clean the data
        • Any preprocessing or transformations applied to the data
      Documenting the data origins is important for understanding the "potential biases, limitations, or quality issues" that might be present in the training data. This can ultimately impact the "performance" and "reliability" of the generative AI model.
  Tools and techniques
   • Data lineage
   • Cataloging
   • Model cards
   "Amazon SageMaker Model Cards"
      document critical details about your ML models in a single place for streamlined governance and reporting.
      Model cards can catalog details, such as the intended use and risk rating of a model, training details and metrics, evaluation results and observations.
      It also catalogs additional call-outs such as considerations, recommendations, and custom information.
      By creating model cards, you can do the following:
        • Provide guidance on how a model should be used.
        • Support audit activities with detailed descriptions of model training and performance.
        • Communicate how a model is intended to support business goals.

Best Practices for Secure Data Engineering
Review of data usage in generative AI
  • User data
      specific inputs or requirements provided by the customers or end-users. This data is used to generate or personalize the output of the generative AI model.
      For all application scopes(from Generative AI Security Scoping Matrix), the customer controls their data. 
  • Fine-tuning data
      This data is used to adapt or fine-tune the pre-trained a generative AI model to the specific needs or preferences of the customers or the application domain.
      The fine-tuning data is typically a subset of the training data or additional data collected from the application domain.
      The fine-tuning process adjusts the model's parameters and weights to better fit the fine-tuning data, allowing the model to generate more relevant and personalized outputs.
      For application Scopes 1 and 2, the application provider controls the fine-tuning data.
      For application Scope 4, the customer controls the fine-tuning data.
  • Training data
      comprehensive dataset used to train the initial pre-trained generative AI model.
      typically a large and diverse collection of data, such as text, images, or audio, depending on the specific application.
      used to build the fundamental knowledge and capabilities of the generative AI model.
      For application Scopes 1, 2, 3, and 4, the application provider controls the training data.
      For application Scope 5, the customer controls the training data.
Data flows in a generative AI application
  <DataFlowsGenAIapp-Final.png>
Data engineering lifecycle
  an iterative process where the data is collected, prepared, and analyzed. This data is then used to train, evaluate, and continuously improve the AI or generative AI models.
  <DataEngineeringLifeCycle-Final.png>
  • Data engineering automation and access control
      Pipeline automation is an important part of modern data-centric architecture design.
      You can use "AWS Glue workflows" to create a pipeline.
  • Data collection
      "Amazon Kinesis", "AWS Database Migration Service (DMS)" and AWS Glue
  • Data preparation and cleaning
      one of the most important, yet most time-consuming, stages of the data lifecycle.
      large workload that has a variety of data, use "Amazon EMR" or AWS Glue
  • Data quality checks
      "AWS Glue DataBrew", and "AWS Glue Data Quality"
  • Data visualization and analysis
      "Amazon QuickSight" - Use to create graphs or charts. 
      "Amazon Neptune" - Use for graph database operations and visualization.
  • Infrastructure as code (IaC) deployment
      "AWS CloudFormation"
  • Monitoring and debugging
      "Amazon CloudWatch"
5.1.c
Best Practices for Secure Data Engineering
  • Assessing data quality
    • Define clear data quality "metrics" and benchmarks such as Completeness, Accuracy, Timeliness and Consistency.
    • Implement "data validation checks" and tests at various stages of the data pipeline.
    • Perform regular data profiling and monitoring to identify data quality issues.
    • Establish a "feedback loop" to address data quality problems and continuously improve.
    • Maintain detailed "data lineage" and metadata to understand the origin and transformation of data.
  • Implementing privacy-enhancing technologies
    • Implement "data masking", data obfuscation, or differential privacy mechanisms to reduce the risk of data breaches.
    • Use "encryption", tokenization, or secure multi-party computation to protect data during processing and storage.
  • Data access control
    • Establish a comprehensive "data governance framework" with clear policies and procedures for data access, usage, and sharing.
    • Implement "role-based access" controls and fine-grained permissions to restrict access to sensitive data.
    • Use "authentication and authorization" mechanisms, such as single sign-on, MFA, or IAM solutions.
    • Monitor and "log all data access activities" to detect and investigate any unauthorized access or anomalies.
    • Regularly review and update access rights based on the principle of least privilege.
  • Data integrity
    quality, accuracy, and reliability of the data used to train the AI models.
    It ensures that the data used for model development, training, and deployment is complete, consistent, and free from errors or inconsistencies.
    • Implement data validation and "integrity checks" at various stages of the data pipeline, such as schema validation, referential integrity checks, and business rule validations.
    • Maintain a robust "data backup" and recovery strategy to ensure data can be restored in case of errors, system failures, or natural disasters.
    • Employ "transaction management" and "atomicity principles" to ensure data consistency and reliability during data processing and transformation.
    • Maintain detailed "data lineage" and audit trails to track the origin, transformations, and changes made to the data.
    • Regularly monitor and test the data integrity controls to ensure their effectiveness and make necessary adjustments.
  "AWS Privacy Reference Architecture"
    offers a set of guidelines to assist in the design and implementation of privacy-supporting controls within AWS services.
    helps make informed decisions regarding the people, processes, and technology that are necessary to ensure privacy in the AWS Cloud environment.
